# -*- coding: utf-8 -*-
"""Snippets: Importing libraries

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/notebooks/snippets/importing_libraries.ipynb

# New section
"""

import numpy as np
from numba import cuda, uint8, uint32

@cuda.jit
def sieve_kernel(start_val, small_primes, bit_array):
    # Mapping: Each thread processes one small prime
    tid = cuda.grid(1)
    if tid < small_primes.size:
        p = small_primes[tid]
        seg_size = len(bit_array) * 8

        first = (start_val + p - 1) // p * p
        if first < p * p: first = p * p

        for m in range(first, start_val + seg_size, p):
            local_idx = m - start_val
            # Agglomeration: Atomic OR to prevent race conditions in the same byte
            cuda.atomic.or_(bit_array, local_idx // 8, uint8(1 << (local_idx % 8)))

def run_gpu_sieve(N, segment_size=10**7):
    # 1. Get small primes on CPU
    sqrt_n = int(N**0.5)
    # ... (same pre-compute as above) ...
    small_primes = np.where(is_prime)[0][2:].astype(np.uint32)

    d_small_primes = cuda.to_device(small_primes)
    num_bytes = (segment_size // 8) + 1

    # Process in chunks (Segmentation)
    for start in range(2, N + 1, segment_size):
        d_bit_array = cuda.to_device(np.zeros(num_bytes, dtype=np.uint8))

        threads = 256
        blocks = (len(small_primes) + threads - 1) // threads
        sieve_kernel[blocks, threads](start, d_small_primes, d_bit_array)

        # Results can be copied back or processed on GPU for Sophie Germain primes
        # result = d_bit_array.copy_to_host()