# -*- coding: utf-8 -*-
"""Snippets: Importing libraries

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/notebooks/snippets/importing_libraries.ipynb

# New section
"""

import numpy as np
from multiprocessing import Pool
import math

def sieve_segment(args):
    start, end, small_primes = args
    size = end - start
    # Bit-packed array for this segment
    seg_bits = np.zeros((size // 8) + 1, dtype=np.uint8)

    for p in small_primes:
        # Find first multiple of p in [start, end]
        first = (start + p - 1) // p * p
        if first < p * p: first = p * p

        for m in range(first, end, p):
            idx = m - start
            seg_bits[idx // 8] |= (1 << (idx % 8))
    return seg_bits

def run_parallel_cpu(N, num_processes=4):
    sqrt_n = int(math.sqrt(N))
    # Pre-compute small primes (Sequential)
    is_prime = np.ones(sqrt_n + 1, dtype=bool)
    for p in range(2, int(sqrt_n**0.5) + 1):
        if is_prime[p]: is_prime[p*p : sqrt_n+1 : p] = False
    small_primes = np.where(is_prime)[0][2:]

    # Partitioning (PCAM: Domain Decomposition)
    seg_size = (N // num_processes)
    tasks = []
    for i in range(num_processes):
        start = i * seg_size + 2
        end = min((i + 1) * seg_size + 2, N + 1)
        tasks.append((start, end, small_primes))

    with Pool(num_processes) as p:
        results = p.map(sieve_segment, tasks)
    return results